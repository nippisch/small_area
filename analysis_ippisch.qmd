---
title: "Analysis Ippisch"
format: html
toc: true
---

# Preparations
```{r}
#| warning: false
load("Workspace Simulation.RData")
library(tidyverse)

rm(d_j_domain, d_jack, d_var_jack, dat_d, dat_d_sampled, dat_pop, dat_var_df, g_mean, sample_d, tmp_df, tmp_df_d, var_boot, var_r, A, base_seed, df, g_bar, g_d, g_jack, g_jack_mean, i, j, jack_d, k, l, m, n_d, name_df, name_df1, R, rows, var_mc_d, var_mc_ij, dat_des_1, dat_des_2, dat_des_3, dat_des_4)

dat_var_1$df <- 1
dat_var_2$df <- 2
dat_var_3$df <- 3
dat_var_4$df <- 4
dat_ges <- rbind(dat_var_1, dat_var_2, dat_var_3, dat_var_4)
```


# First descriptive look
```{r}
dat_fin$diff_bias <- dat_fin$bias_boot - dat_fin$bias_jack
dat_fin$diff_rsme <- dat_fin$RSME_boot - dat_fin$RSME_jack
dat_fin$rel_bias_boot <- dat_fin$bias_boot / dat_fin$var_mc
dat_fin$rel_bias_jack <- dat_fin$bias_jack / dat_fin$var_mc
summary(dat_fin)

```

Bias of bootstrap on average a little bit positive --> $\hat{Var}_{boot}$ on average smaller than $\hat{Var}_{MC}$ --> bootstrap seems to overestimate the variance on average a little bit
Bias of Jackknife same, but a little bit bigger on average than bootstrap

```{r}
dat_fin |> 
  ggplot(aes(x = bias_boot, y = bias_jack)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, col = "blue")
```

Average RSME of bootstrap little bit smaller than Jackknife.

```{r}
dat_fin |> 
  ggplot(aes(x = RSME_boot, y = RSME_jack)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, col = "blue")
```

## Densities of bootstrap variance estimators

```{r}
#| warning: false
p_b_1 <- dat_ges |> 
  filter(df == 1) |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[1, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[2, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[3, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[4, "var_mc"], col = "purple") +
  labs(title = "Uniform Distribution",
       x = "Bootstrap estimators",
       y = "Density") +
  xlim(0, 0.0000004) +
  ylim(0, 800000000)
p_b_2 <- dat_ges |> 
  filter(df == 2) |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[5, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[6, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[7, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[8, "var_mc"], col = "purple") +
  labs(title = "Gamma Distribution",
       x = "Bootstrap estimators",
       y = "Density") +
  xlim(0, 0.005) +
  ylim(0, 50000)
p_b_3 <- dat_ges |> 
  filter(df == 3) |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[9, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[10, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[11, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[12, "var_mc"], col = "purple") +
  labs(title = "Log-Normal Distribution",
       x = "Bootstrap estimators",
       y = "Density") +
  xlim(0, 0.0007) +
  ylim(0, 100000)
p_b_4 <- dat_ges |> 
  filter(df == 4) |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[13, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[14, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[15, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[16, "var_mc"], col = "purple") +
  labs(title = "Dagum Distribution",
       x = "Bootstrap estimators",
       y = "Density") +
  xlim(0, 0.004) +
  ylim(0, 30000)
ggpubr::ggarrange(p_b_1, p_b_2, p_b_3, p_b_4, nrow = 2, ncol = 2, common.legend = TRUE)
```

## Densities of jackknife variance estimators

```{r}
#| warning: false
p_j_1 <- dat_ges |> 
  filter(df == 1) |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[1, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[2, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[3, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[4, "var_mc"], col = "purple") +
  labs(title = "Uniform Distribution",
       x = "Jackknife estimators",
       y = "Density") +
  xlim(0, 0.0000004) +
  ylim(0, 800000000)
p_j_2 <- dat_ges |> 
  filter(df == 2) |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[5, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[6, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[7, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[8, "var_mc"], col = "purple") +
  labs(title = "Gamma Distribution",
       x = "Jackknife estimators",
       y = "Density") +
  xlim(0, 0.005) +
  ylim(0, 50000)
p_j_3 <- dat_ges |> 
  filter(df == 3) |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[9, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[10, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[11, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[12, "var_mc"], col = "purple") +
  labs(title = "Log-Normal Distribution",
       x = "Jackknife estimators",
       y = "Density") +
  xlim(0, 0.0007) +
  ylim(0, 100000)
p_j_4 <- dat_ges |> 
  filter(df == 4) |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  geom_vline(xintercept = dat_fin[13, "var_mc"], col = "red") +
  geom_vline(xintercept = dat_fin[14, "var_mc"], col = "green") +
  geom_vline(xintercept = dat_fin[15, "var_mc"], col = "blue") +
  geom_vline(xintercept = dat_fin[16, "var_mc"], col = "purple") +
  labs(title = "Dagum Distribution",
       x = "Jackknife estimators",
       y = "Density") +
  xlim(0, 0.004) +
  ylim(0, 30000)
ggpubr::ggarrange(p_j_1, p_j_2, p_j_3, p_j_4, nrow = 2, ncol = 2, common.legend = TRUE)
```

```{r}
#| warning: false
ggpubr::ggarrange(p_b_1, p_b_2, p_j_1, p_j_2, p_b_3, p_b_4, p_j_3, p_j_4, nrow = 2, ncol = 4, common.legend = TRUE)
```

## Bias of bootstrap and jackknife over dataframes per domain

```{r}
dat_ges |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  facet_wrap( ~ df, scales = "free")
```

```{r}
dat_ges |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  facet_wrap( ~ df, scales = "free")
```

```{r}
plot_boot_all <- dat_ges |> 
  ggplot(aes(boot, fill = domain)) +
  geom_density() +
  facet_wrap( ~ df, scales = "free") +
  labs(x = "Bootstrap variance estimator",
       y = "Density",
       fill = "Domain")

plot_jack_all <- dat_ges |> 
  ggplot(aes(jack, fill = domain)) +
  geom_density() +
  facet_wrap( ~ df, scales = "free")+
  labs(x = "Jackknife variance estimator",
       y = "",
       fill = "Domain")
ggpubr::ggarrange(plot_boot_all, plot_jack_all, nrow = 1, ncol = 2, common.legend = TRUE)
```

## Relative Bias

Relative Bias of jackknife in mean and median higher, also higher max value.

```{r}
dat_fin |> 
  arrange(rel_bias_boot, descending = TRUE) |> 
  tail(n = 5) |> 
  select(df, domain, var_mc, bias_boot, RSME_boot, rel_bias_boot)
```

Bootstrap: Highest relative bias for domain 1 of df2, followed by d4 of df2 and d2 of df2. Interestingly, the fourth-highest relative bias is visible for d1 of df1 (uniform distribution).

```{r}
dat_fin |> 
  arrange(rel_bias_jack, descending = FALSE) |> 
  tail(n = 5) |> 
  select(df, domain, var_mc, bias_jack, RSME_jack, rel_bias_jack)
```

Highest relative bias for d1 in df2, followed by d2 in df2 and d4 in df2 (same domains and df as highest bias for bootstrap).

For uniform distribution, the relative bias of bootstrap is higher for the two small domains and lower for the two big domains. For the gamma distribution, the relative bias of bootstrapping is lower for all domains. The same is true for df3 (log-normal) and the dagum distribution. Thus, the only domain-df-combinations for which the absolute relative bias of jackknife is smaller than of bootstrap is for the small domains (d1 and d2) of the uniform distribution - for all other combinations, bootstrapping has a smaller absolute relative bias.

```{r}
dat_fin |> 
  ggplot(aes(x = rel_bias_boot, y = rel_bias_jack)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 1, col = "blue") +
  ylim(0, 0.5) +
  xlim(-0.1, 0.5)
```

# Difference in mean

## Tests across all dataframes and domains

```{r}
t.test(dat_fin$bias_boot, dat_fin$bias_jack, alternative = "two.sided")
```

```{r}
t.test(dat_fin$rel_bias_boot, dat_fin$rel_bias_jack, alternative = "two.sided")
```


```{r}
t.test(dat_fin$RSME_boot, dat_fin$RSME_jack, alternative = "two.sided")
```
Across all domains and dataframes, no significant difference between bootstrap and Jackknife, neither for bias nor for RSME.


# Analysis per df

```{r}
dat_fin |> 
  group_by(df) |> 
  summarise(mean_bias_boot = mean(bias_boot),
            mean_bias_jack = mean(bias_jack),
            mean_RSME_boot = mean(RSME_boot),
            mean_RSME_jack = mean(RSME_jack))
```
Bootstrap: Bias biggest for df2 (Gamma) and smallest for df1 (uniform) and positive for all dataframes. RSME is for df4 (Dagum) biggest and for uniform smallest again.

Jackknife: Bias for Gamma biggest and for uniform smallest and positive for all dataframes (same as bootstrap). RSME For Gamma the biggest and for uniform smallest (bootstrap has biggest RSME for df4).

# Analysis per domain

```{r}
dat_fin |> 
  group_by(domain) |> 
  summarise(mean_bias_boot = mean(bias_boot),
            mean_bias_jack = mean(bias_jack),
            mean_RSME_boot = mean(RSME_boot),
            mean_RSME_jack = mean(RSME_jack))
```
Bootstrap: Bias decreases for increasing sample size but d3 has lower bias than d4, all biases positive again. RSME also decreases for increasing sample size.

Jackknife: Bias overall decreases with increasing sample size but d3 has smaller bias than d4. For RSME the same.

# Analysis per df and domain

## Bootstrap
Bias of bootstrap everywhere positive except of df3 d1. All domains (4 < 3 < 2 < 1) of df1 have the smallest bias, d1 of df2 has the biggest (followed by d2 of df2 and d2 of df4).
RSME is smallest again for df1 as above. Highest RSME for d1 of df4 and df2.

## Jackknife
Bias everywhere positive. Again, all domains of df1 have the smallest bias. d1 of df2 and df4 have the biggest bias. RSME smallest for d1 and biggest for d1 of df2 and df4 again.

# Difference of Jackknife and Bootstrap

bias_boot - bias_jack and RSME_boot - RSME_jack

The Bias of Jackknife is for all df and domains bigger than the one of Bootstrap except d1 and d2 of df1. The biggest differences are visible for d1 of df2 and df4 (where the absolute bias is also higher), the smallest differences are visible for d1.

For RSME, the picture is more differentiated: RSME of Jackknife tends to be bigger for the small domains. RSME of Bootstrap tends to be bigger for the domains with larger sample size, even though the absolute difference decreases with increasing domain size.

# Coverage

```{r}

dat_ges$lower_boot <- dat_ges$gini - 1.96 * sqrt(dat_ges$boot)
dat_ges$upper_boot <- dat_ges$gini + 1.96 * sqrt(dat_ges$boot)

dat_ges$lower_jack <- dat_ges$gini - 1.96 * sqrt(dat_ges$jack)
dat_ges$upper_jack <- dat_ges$gini + 1.96 * sqrt(dat_ges$jack)

df <- 4
d <- 4
dat_gini_gt <- data.frame(df = numeric(0), d = character(0), gini = numeric(0))
row = 1
for (i in 1:df) {
  tmp_df <- dat_inc[, c(i, 5)]
  
  for (j in 1:d) {
    tmp_d <- tmp_df |> 
      filter(domain == paste0("d", j))
    gini <- ineq::Gini(tmp_d[, 1])
    dat_gini_gt[row, "df"] <- i
    dat_gini_gt[row, "d"] <- j
    dat_gini_gt[row, "gini"] <- gini
    
    for (k in 1:nrow(dat_ges)) {
      if(dat_ges$df[k] == i & dat_ges$domain[k] == paste0("d", j)){
        dat_ges$cov_boot[k] <- ifelse(dat_ges$lower_boot[k] < gini & dat_ges$upper_boot[k] > gini, 1, 0)
        dat_ges$cov_jack[k] <- ifelse(dat_ges$lower_jack[k] < gini & dat_ges$upper_jack[k] > gini, 1, 0)
      }
    }
    
    row = row + 1
    
  }
}

dat_cov <- dat_ges |> 
  group_by(df, domain) |> 
  summarise(cov_boot = mean(cov_boot), 
            cov_jack = mean(cov_jack))

dat_fin <- cbind(dat_fin, dat_cov[, 3:4])

dat_cov

```

```{r}
dat_fin$dfd <- paste0(dat_cov$df, "_", dat_cov$domain)
dat_fin$cov95_boot <- ifelse(dat_fin$cov_boot > 0.95, 1, 0)
dat_fin$cov95_jack <- ifelse(dat_fin$cov_jack > 0.95, 1, 0)
dat_fin |> 
  ggplot(aes(x = dfd, y = cov_boot, fill = as.factor(cov95_boot))) +
  geom_col() +
  geom_abline(slope = 0, intercept = 0.95, col = "red") +
  geom_label(aes(label = round(rel_bias_boot, 2)), size = 2) +
  labs(fill = "Coverage > 0.95?",
        x = "Dataframe_Domain",
        y = "Coverage (Bootstrap)") +
  scale_fill_discrete(palette = c("red3", "green4"))
```


```{r}
dat_cov_long <- dat_cov |> 
  pivot_longer(cols = c(cov_boot, cov_jack),
               names_to = "type",
               values_to = "cov")
dat_cov_long$dfd <- paste0(dat_cov_long$df, "_", dat_cov_long$domain)
dat_cov_long$cov95 <- ifelse(dat_cov_long$cov > 0.95, 1, 0)

```

```{r}
dat_cov_long |> 
  filter(type == "cov_jack") |> 
  ggplot(aes(x = dfd, y = cov, fill = as.factor(cov95))) +
  geom_col() +
  geom_abline(slope = 0, intercept = 0.95, col = "red") +
  labs(fill = "Coverage > 0.95?",
        x = "Dataframe_Domain",
        y = "Coverage (Jackknife)") +
  scale_fill_discrete(palette = c("red3", "green4"))
```


```{r}
dat_cov$boot_95 <- ifelse(dat_cov$cov_boot > 0.95, 1, 0)
dat_cov$jack_95 <- ifelse(dat_cov$cov_jack > 0.95, 1, 0)
dat_cov |> 
  ungroup() |> 
  summarise(ratio_cov_boot = mean(boot_95),
            ratio_cov_jack = mean(jack_95))
```


# Analysis of Gini

```{r}
dat_ges |> 
  ggplot(aes(gini, fill = domain)) +
  geom_density(alpha = 0.4) +
  facet_wrap( ~ df, scales = "free") +
  labs(x = "Gini estimator per dataframe and domain",
       y = "Density",
       fill = "Domain")
```


```{r}
gini_1 <- dat_var_1 |> 
  filter(domain == "d1") |> 
  ggplot(aes(x = R, y = gini)) +
  geom_line() +
  geom_abline(slope = 0, intercept = ineq::Gini(dat_inc$uniform[dat_inc$domain == "d1"]), col = "blue") +
  labs(y = paste("Gini; Range:", round(max(dat_var_1$gini) - min(dat_var_1$gini), 2)),
       x = "MC-Iteration",
       title = "Uniform")
gini_2 <- dat_var_2 |> 
  filter(domain == "d1") |> 
  ggplot(aes(x = R, y = gini)) +
  geom_line() +
  geom_abline(slope = 0, intercept = ineq::Gini(dat_inc$gamma[dat_inc$domain == "d1"]), col = "blue") +
  labs(y = paste("Gini; Range:", round(max(dat_var_2$gini) - min(dat_var_2$gini), 2)),
       x = "MC-Iteration",
       title = "Gamma")
gini_3 <- dat_var_3 |> 
  filter(domain == "d1") |> 
  ggplot(aes(x = R, y = gini)) +
  geom_line() +
  geom_abline(slope = 0, intercept = ineq::Gini(dat_inc$lognormal[dat_inc$domain == "d1"]), col = "blue") +
  labs(y = paste("Gini; Range:", round(max(dat_var_3$gini) - min(dat_var_3$gini), 2)),
       x = "MC-Iteration",
       title = "Log-Normal")
gini_4 <- dat_var_4 |> 
  filter(domain == "d1") |> 
  ggplot(aes(x = R, y = gini)) +
  geom_line() +
  geom_abline(slope = 0, intercept = ineq::Gini(dat_inc$dagum[dat_inc$domain == "d1"]), col = "blue") +
  labs(y = paste("Gini; Range:", round(max(dat_var_4$gini) - min(dat_var_4$gini), 2)),
       x = "MC-Iteration",
       title = "Dagum")
ggpubr::ggarrange(gini_1, gini_2, gini_3, gini_4, nrow = 2, ncol = 2)
```

Even tough the mean Gini is higher for the Gamma distribution, the absolute range (max - min) is bigger for the Dagum distribution (all graphs just for d1).

```{r}
t.test(dat_var_1$boot, dat_var_1$jack, alternative = "two.sided")
```






